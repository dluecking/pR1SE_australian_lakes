Building DAG of jobs...
Using shell: /bin/bash
Provided cluster nodes: 1
Conda environments: ignored
Job stats:
job                 count    min threads    max threads
----------------  -------  -------------  -------------
iterative_blastp        1              1              1
total                   1              1              1

Select jobs to execute...

[Fri Apr 21 11:55:37 2023]
rule iterative_blastp:
    input: initial_proteins/ORF6_initial_proteins.faa
    output: blastp2_proteins/ORF6_blastp_proteins.faa
    jobid: 0
    wildcards: ORF=ORF6
    resources: tmpdir=/tmp, mem=50GB, threads=4, time=10:00:00, partition=CLUSTER

Submitted job 0 with external jobid 'Submitted batch job 61603'.
[Fri Apr 21 11:55:47 2023]
Error in rule iterative_blastp:
    jobid: 0
    output: blastp2_proteins/ORF6_blastp_proteins.faa
    shell:
        
    python3 scripts/01_iterative_blast.py     initial_proteins/ORF6_initial_proteins.faa blastp2_proteins/ORF6_blastp_proteins.faa --db /bioinf/home/dlueckin/dbs/diamond_nr/nr.dmnd     --evalue 1e-05     --bitscore 50 
    
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 61603

Error executing rule iterative_blastp on cluster (jobid: 0, external: Submitted batch job 61603, jobscript: /home/dlueckin/projects/pR1SE_australian_lakes/generate_protein_clusters/.snakemake/tmp.v4qqev5c/snakejob.iterative_blastp.0.sh). For error details see the cluster log and the log files of the involved rule(s).
Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
