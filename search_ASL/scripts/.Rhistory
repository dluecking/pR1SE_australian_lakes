# libraries ---------------------------------------------------------------
library(data.table)
library(stringr)
library(seqinr)
library(tidyr)
library(ggplot2)
library(dplyr)
# working directory -------------------------------------------------------
this_dir <- dirname(rstudioapi::getSourceEditorContext()$path)
setwd(this_dir)
print(paste0("Setting wd to: \n ", this_dir))
host_df <- fread("known_hosts_df.tsv")
View(host_df)
# Search for taxonomy ID of organism
search_term <- "Halorubrum aethiopicum"
search_results <- entrez_search(db="taxonomy", term=search_term)
tax_id <- search_results$ids[1]
# Download GenBank file for organism
gb <- entrez_fetch(db="nucleotide", id=tax_id, rettype="gb", retmode="text")
gb
write(gb, "here.txt")
# Search for taxonomy ID of organism
search_term <- "Halorubrum aethiopicum"
search_results <- entrez_search(db="taxonomy", term=search_term)
search_results
unlist(search_results)
tax_id
# Download GenBank file for organism
fasta <- entrez_fetch(db="nucleotide", id=tax_id, rettype="fasta", retmode="text")
write(fasta, "here.txt")
tax_id <- search_results$ids[1]
tax_id
fasta
tax_id
taxid <- tax_id
# Search the Nucleotide database for the taxid
search_result <- entrez_search(db = "nucleotide", term = paste0("txid", taxid, "[Organism:exp]"))
# Get the list of ids for the search results
id_list <- search_result$ids
id_list
View(search_result)
View(host_df)
prot_df <- fread("prot_df.tsv")
View(prot_df)
protein_acc <- "WP_004048516.1"
# Use entrez_link() to retrieve the GenBank accession number associated with the protein accession
link_result <- entrez_link(dbfrom = "protein", id = protein_acc, db = "nuccore")
link_result
link_result$links
# Extract the GenBank accession number from the link_result
gb_acc <- link_result$links$nuccore_protein_seq[1]
gb_acc
link_result$links
# Extract the GenBank accession number from the link_result
gb_acc <- link_result$links$protein_nuccore_wp[1]
gb_acc
# Use entrez_link() to retrieve the GenBank accession number associated with the protein accession
link_result <- entrez_link(dbfrom = "protein", id = protein_acc, db = "nuccore")
# Extract the GenBank accession number from the link_result
gb_acc <- link_result$links$protein_nuccore_wp[1]
# Use readGenBank() to download the GenBank file for the corresponding genome
genome_gb <- readGenBank(gb_acc, format = "gb")
# get the nucleotide accession number for the protein
search_term <- paste0(protein_accession, "[Protein Accession]")
# get the nucleotide accession number for the protein
search_term <- paste0(protein_acc, "[Protein Accession]")
esearch_result <- entrez_search(db = "nucleotide", term = search_term)
esearch_result
protein_acc
# get the nucleotide accession number for the protein
search_term <- paste0(protein_acc, "[Protein Accession]")
search_term
entrez_summary(db="protein", id=protein_acc)
a <- entrez_summary(db="protein", id=protein_acc)
a
a["genome"]
View(a)
a["gi"]
entrez_summary(db="uid", id=2248)
entrez_search(db = "nucleotide", term = paste0("uid", 2248, "[uid]")
)
# author: dlueckin
# date: Wed May 10 15:18:46 2023
# libraries ---------------------------------------------------------------
library(data.table)
library(stringr)
library(seqinr)
library(tidyr)
library(ggplot2)
library(dplyr)
library(rentrez)
# working directory -------------------------------------------------------
this_dir <- dirname(rstudioapi::getSourceEditorContext()$path)
setwd(this_dir)
print(paste0("Setting wd to: \n ", this_dir))
# import df ---------------------------------------------------------------
host_df <- fread("known_hosts_df.tsv")
View(host_df)
get_genome_accession <- function(protein_accession) {
# Use efetch to retrieve the protein's related nucleotide sequence
nucl_seq <- rentrez::efetch(db = "protein", id = protein_accession, rettype = "fasta", retmode = "text")
# Extract the nucleotide accession from the sequence header
nucl_acc <- sub(".*\\|(.*)\\|.*", "\\1", nucl_seq)
# Use efetch to retrieve the nucleotide record
nucl_record <- rentrez::efetch(db = "nuccore", id = nucl_acc, rettype = "gb", retmode = "text")
# Extract the genome accession from the nucleotide record
genome_acc <- sub(".*ACCESSION\\s+(\\w+).*", "\\1", nucl_record)
# Return the genome accession
return(genome_acc)
}
# Example usage
protein_acc <- "WP_004048516"
# Use efetch to retrieve the protein's related nucleotide sequence
nucl_seq <- rentrez::efetch(db = "protein", id = protein_accession, rettype = "fasta", retmode = "text")
# Use efetch to retrieve the protein's related nucleotide sequence
nucl_seq <- rentrez::efetch(db = "protein", id = protein_accession, rettype = "fasta", retmode = "text")
library(rentrez)
# Use efetch to retrieve the protein's related nucleotide sequence
nucl_seq <- rentrez::efetch(db = "protein", id = protein_accession, rettype = "fasta", retmode = "text")
# Use efetch to retrieve the protein's related nucleotide sequence
nucl_seq <- rentrez::entrez_fetch(db = "protein", id = protein_accession, rettype = "fasta", retmode = "text")
all_the_links <- entrez_link(dbfrom='protein', id = "WP_004048516", db='all')
all_the_links
all_the_links$links
all_the_links$links[1]
all_the_links$links[2]
all_the_links$links[3]
all_the_links$links[4]
all_the_links$links[5]
all_the_links$links[6]
all_the_links <- entrez_link(dbfrom='taxid', id = "2248", db='all')
all_the_links <- entrez_link(dbfrom='taxonomy', id = "2248", db='all')
all_the_links
all_the_links$links
all_the_links$links$taxonomy_genome
entrez_fetch(db = "genome", id = 16377, rettype = rettype, retmode = retmode)
entrez_link(dbfrom='protein', id = "WP_004048516", db='all')
# author: dlueckin
# date: Wed May 10 15:18:46 2023
# libraries ---------------------------------------------------------------
library(data.table)
library(stringr)
library(seqinr)
library(tidyr)
library(ggplot2)
library(dplyr)
library(rentrez)
# working directory -------------------------------------------------------
this_dir <- dirname(rstudioapi::getSourceEditorContext()$path)
setwd(this_dir)
print(paste0("Setting wd to: \n ", this_dir))
# import df ---------------------------------------------------------------
host_df <- fread("known_hosts_df.tsv")
# get protein links
protein_links <- entrez_link(dbfrom='protein', id = "WP_004048516", db='all')
# author: dlueckin
# date: Wed May 10 15:18:46 2023
# libraries ---------------------------------------------------------------
library(data.table)
library(stringr)
library(seqinr)
library(tidyr)
library(ggplot2)
library(dplyr)
library(rentrez)
# working directory -------------------------------------------------------
this_dir <- dirname(rstudioapi::getSourceEditorContext()$path)
setwd(this_dir)
print(paste0("Setting wd to: \n ", this_dir))
# import df ---------------------------------------------------------------
host_df <- fread("known_hosts_df.tsv")
acc <- "WP_004048516"
# get protein links
protein_links <- entrez_link(dbfrom='protein', id = acc, db='all')
protein_links$links
protein_links$links$protein_taxonomy
protein_links$links$protein_taxonomy_wp2species
# use taxid number to get taxid links
tax_id <- protein_links$links$protein_taxonomy
tax_links <- entrez_link(dbfrom='taxonomy', id = tax_id, db='all')
tax_links
tax_links$links$taxonomy_genome
# get genome based on taxid
genome_id <- tax_links$links$taxonomy_genome
genome_fasta <- entrez_fetch(db = "nucleotide", id = genome_id, rettype = "fasta")
genome_id
genome_fasta <- entrez_fetch(db = "nuccore", id = genome_id, rettype = "fasta")
tax_id
genome_id
tax_links
tax_links$links
search_term <- paste(genome_acc, "[Assembly]", sep="")
search_term <- paste(genome_id, "[Assembly]", sep="")
# Search for the genome using the search term
search_results <- entrez_search(db = "nucleotide", term = search_term)
search_results
search_term <- paste(genome_id, "[uid]", sep="")
# Search for the genome using the search term
search_results <- entrez_search(db = "nucleotide", term = search_term)
search_results
tax_id
genome_id
# set up NCBI API parameters
db <- "nuccore"
id <- genome_id
rettype <- "gb"
# construct the download URL
url <- paste0("https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=", db, "&id=", id, "&rettype=", rettype)
url
# download the file and save it
download.file(url, destfile = file_name, mode = "wb")
# download the file and save it
download.file(url, destfile = "here", mode = "wb")
id <- "NZ_AOJE01000051.1"
rettype <- "gb"
# construct the download URL
url <- paste0("https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=", db, "&id=", id, "&rettype=", rettype)
# download the file and save it
download.file(url, destfile = "here", mode = "wb")
View(host_df)
# author: dlueckin
# date: Wed May 10 15:18:46 2023
# libraries ---------------------------------------------------------------
library(data.table)
library(stringr)
library(seqinr)
library(tidyr)
library(ggplot2)
library(dplyr)
library(rentrez)
# working directory -------------------------------------------------------
this_dir <- dirname(rstudioapi::getSourceEditorContext()$path)
setwd(this_dir)
print(paste0("Setting wd to: \n ", this_dir))
# import df ---------------------------------------------------------------
prot_df <- fread("prot_df.tsv")
#  old --------------------------------------------------------------------
host_df <- fread("known_hosts_df.tsv")
acc <- "WP_004048516"
# get protein links
protein_links <- entrez_link(dbfrom='protein', id = acc, db='all')
# use taxid number to get taxid links
tax_id <- protein_links$links$protein_taxonomy
tax_links <- entrez_link(dbfrom='taxonomy', id = tax_id, db='all')
# author: dlueckin
# date: Wed May 10 15:18:46 2023
# libraries ---------------------------------------------------------------
library(data.table)
library(stringr)
library(seqinr)
library(tidyr)
library(ggplot2)
library(dplyr)
library(rentrez)
# working directory -------------------------------------------------------
this_dir <- dirname(rstudioapi::getSourceEditorContext()$path)
setwd(this_dir)
print(paste0("Setting wd to: \n ", this_dir))
# import df ---------------------------------------------------------------
prot_df <- fread("prot_df.tsv")
View(prot_df)
protein_accession <- prot_df$acc[10]
# use efetch to retrieve the summary for the protein accession
summary_result <- entrez_summary(db = "protein", id = protein_accession)
# extract the related genome accession from the summary result
genome_accession <- summary_result[["related_ids"]][grep("nucleotide", summary_result[["related_db"]])]
summary_result
summary_result[["strain"]]
for(i in 1:length(summary_result)){print(summary_result[[i]])}
protein_accession <- "WP_004048516"
# use efetch to retrieve the summary for the protein accession
summary_result <- entrez_summary(db = "protein", id = protein_accession)
for(i in 1:length(summary_result)){print(summary_result[[i]])}
summary_result
summary_result[["genome"]]
taxid <- 2248
query <- paste0("txid", taxid, "[Organism:exp] AND srcdb_refseq[PROP] AND biomol_genomic[PROP] NOT anomalous[PROP]")
query
esearch <- entrez_search(db = "nucleotide", term = query)
esearch
esearch
query <- paste0("txid", taxid, "[Organism:exp]")
esearch <- entrez_search(db = "nucleotide", term = query)
esearch
esearch$ids
id_list <- esearch$ids
esummary <- entrez_summary(db = "nucleotide", id = id_list)
genbank_accessions <- esummary$caption[grepl("genbank", esummary$caption)]
genbank_accessions
id_list
# Set the database and the ID type
db <- "nuccore"
id_type <- "acc"
# Construct the query
query <- paste0(id_type, "[accn]", "448447358")
# Search NCBI with the query
search <- entrez_search(db, term = query)
search
# author: dlueckin
# date: Wed May 10 15:18:46 2023
# libraries ---------------------------------------------------------------
library(data.table)
library(stringr)
library(seqinr)
library(tidyr)
library(ggplot2)
library(dplyr)
library(rentrez)
# working directory -------------------------------------------------------
this_dir <- dirname(rstudioapi::getSourceEditorContext()$path)
setwd(this_dir)
print(paste0("Setting wd to: \n ", this_dir))
# import df ---------------------------------------------------------------
prot_df <- fread("prot_df.tsv")
protein_accession <- "WP_004048516"
taxid <- 2248
# author: dlueckin
# date: Fri Apr 21 15:15:13 2023
# libraries ---------------------------------------------------------------
library(data.table)
library(stringr)
library(seqinr)
library(tidyr)
library(ggplot2)
library(dplyr)
library(readxl)
# working directory -------------------------------------------------------
this_dir <- dirname(rstudioapi::getSourceEditorContext()$path)
setwd(this_dir)
print(paste0("Setting wd to: \n ", this_dir))
# load input dataframe ----------------------------------------------------
df <- fread("input/MS117_LAR_Multiconsensus_UnfilteredDatabase.csv", skip = 1) %>%
select(Accession, "MW [kDa]", starts_with("# PSMs (by Search Engine)"))
df <- fread("input/new/MS117_LAR_Multiconsensus_UnfilteredDatabase.csv", skip = 1) %>%
select(Accession, "MW [kDa]", starts_with("# PSMs (by Search Engine)"))
df <- fread("input/MS117_LAR_Multiconsensus_UnfilteredDatabase.csv", skip = 1) %>%
select(Accession, "MW [kDa]", starts_with("# PSMs (by Search Engine)"))
df <- fread("input/new/MS117_LAR_Multiconsensus_UnfilteredDatabase.csv", skip = 1) %>%
select(Accession, "MW [kDa]", starts_with("# PSMs (by Search Engine)"))
df <- fread("input/MS117_LAR_Multiconsensus_UnfilteredDatabase.csv", skip = 1) %>%
select(Accession, "MW [kDa]", starts_with("# PSMs (by Search Engine)"))
df2 <- fread("input/new/MS117_LAR_Multiconsensus_UnfilteredDatabase.csv", skip = 1) %>%
select(Accession, "MW [kDa]", starts_with("# PSMs (by Search Engine)"))
View(df2)
View(df)
View(df2)
View(df)
# author: dlueckin
# date: Tue May  9 13:14:32 2023
# libraries ---------------------------------------------------------------
library(data.table)
library(stringr)
library(seqinr)
library(tidyr)
library(ggplot2)
library(dplyr)
# working directory -------------------------------------------------------
this_dir <- dirname(rstudioapi::getSourceEditorContext()$path)
setwd(this_dir)
print(paste0("Setting wd to: \n ", this_dir))
# explore -----------------------------------------------------------------
lakes <- fread("list_of_lakes.txt", header = FALSE)
orf_df <- fread("ORF_cutoff_table.tsv")
big_df <- data.table()
for(file in list.files("../01_hmm_results", full.names = TRUE, pattern = "domtblout.txt")){
is_not_empty <- as.numeric(str_split(system(command = paste0("wc -l ", file), intern = TRUE), " ")[[1]][1]) > 13
if(is_not_empty){
domtbl <- fread(file, skip = 3, fill = TRUE) %>%
select(V1, V3, V4, V6, V7, V8, V16, V17) %>%
filter(V1 != "#")
names(domtbl) <- c("hit", "hit_length", "query", "query_length", "evalue", "score", "alignment_start", "alignment_end")
current_lake <- str_extract(file, pattern = paste(lakes$V1, collapse = "|"))
domtbl$lake <- current_lake
current_ORF <- str_extract(file, pattern = "ORF[^\\_]*")
# calc alignment length
domtbl$aln_length <- domtbl$alignment_end - domtbl$alignment_start
# prepare data for later filtering
domtbl$query_length <- as.numeric(domtbl$query_length)
domtbl$score <- as.numeric(domtbl$score)
domtbl <- domtbl %>%
filter(score >= 50)
# filter(score >= orf_df[orf_df$orf == current_ORF]$min_score) %>%
# filter(aln_length >= orf_df[orf_df$orf == current_ORF]$min_alignment_length)
big_df <- rbind(big_df, domtbl)
}
}
big_df$contig <- paste0(big_df$lake, "_", str_extract(big_df$hit, "megahit\\_\\d*"))
View(big_df)
big_df$contig <- str_remove(big_df$hit, pattern = "\\_length.*")
table(big_df$contig)
contig_df <- data.table(table(big_df$contig))
View(contig_df)
contig_df %>% filter(N >= 4)
# author: dlueckin
# date: Fri Apr 21 15:15:13 2023
# libraries ---------------------------------------------------------------
library(data.table)
library(stringr)
library(seqinr)
library(tidyr)
library(ggplot2)
library(dplyr)
library(readxl)
# working directory -------------------------------------------------------
this_dir <- dirname(rstudioapi::getSourceEditorContext()$path)
setwd(this_dir)
print(paste0("Setting wd to: \n ", this_dir))
df <- fread("input/MS117_LAR_Multiconsensus_UnfilteredDatabase.csv", skip = 1) %>%
select(Accession, "MW [kDa]", starts_with("# PSMs (by Search Engine)"))
View(df)
library(gggenes)
# author: dlueckin
# date: Tue May  9 13:14:32 2023
# libraries ---------------------------------------------------------------
library(data.table)
library(stringr)
library(seqinr)
library(tidyr)
library(ggplot2)
library(dplyr)
# working directory -------------------------------------------------------
this_dir <- dirname(rstudioapi::getSourceEditorContext()$path)
setwd(this_dir)
print(paste0("Setting wd to: \n ", this_dir))
# explore -----------------------------------------------------------------
lakes <- fread("list_of_lakes.txt", header = FALSE)
orf_df <- fread("ORF_cutoff_table.tsv")
big_df <- data.table()
for(file in list.files("../01_hmm_results", full.names = TRUE, pattern = "domtblout.txt")){
is_not_empty <- as.numeric(str_split(system(command = paste0("wc -l ", file), intern = TRUE), " ")[[1]][1]) > 13
if(is_not_empty){
domtbl <- fread(file, skip = 3, fill = TRUE) %>%
select(V1, V3, V4, V6, V7, V8, V16, V17) %>%
filter(V1 != "#")
names(domtbl) <- c("hit", "hit_length", "query", "query_length", "evalue", "score", "alignment_start", "alignment_end")
current_lake <- str_extract(file, pattern = paste(lakes$V1, collapse = "|"))
domtbl$lake <- current_lake
current_ORF <- str_extract(file, pattern = "ORF[^\\_]*")
# calc alignment length
domtbl$aln_length <- domtbl$alignment_end - domtbl$alignment_start
# prepare data for later filtering
domtbl$query_length <- as.numeric(domtbl$query_length)
domtbl$score <- as.numeric(domtbl$score)
domtbl <- domtbl %>%
filter(score >= 50)
# filter(score >= orf_df[orf_df$orf == current_ORF]$min_score) %>%
# filter(aln_length >= orf_df[orf_df$orf == current_ORF]$min_alignment_length)
big_df <- rbind(big_df, domtbl)
}
}
big_df$contig <- str_remove(big_df$hit, pattern = "\\_length.*")
View(big_df)
big_df$contig <- str_remove(big_df$hit, pattern = "\\_length.*")
bid_df$contig_len <- as.numeric(str_remove(str_extrac(big_df$hit, "length\\_\\d*"), "length\\_"))
bid_df$contig_len <- as.numeric(str_remove(str_extract(big_df$hit, "length\\_\\d*"), "length\\_"))
big_df$contig_len <- as.numeric(str_remove(str_extract(big_df$hit, "length\\_\\d*"), "length\\_"))
big_df %>% filter(length >= 10000)
View(big_df)
big_df$contig <- str_remove(big_df$hit, pattern = "\\_length.*")
contig_df <- data.table(table(big_df$contig))
contig_df$contig_len <- big_df$contig_len[match(big_df$contig, contig_df$V1)]
# author: dlueckin
# date: Tue May  9 13:14:32 2023
# libraries ---------------------------------------------------------------
library(data.table)
library(stringr)
library(seqinr)
library(tidyr)
library(ggplot2)
library(dplyr)
# working directory -------------------------------------------------------
this_dir <- dirname(rstudioapi::getSourceEditorContext()$path)
setwd(this_dir)
print(paste0("Setting wd to: \n ", this_dir))
# explore -----------------------------------------------------------------
lakes <- fread("list_of_lakes.txt", header = FALSE)
orf_df <- fread("ORF_cutoff_table.tsv")
big_df <- data.table()
for(file in list.files("../01_hmm_results", full.names = TRUE, pattern = "domtblout.txt")){
is_not_empty <- as.numeric(str_split(system(command = paste0("wc -l ", file), intern = TRUE), " ")[[1]][1]) > 13
if(is_not_empty){
domtbl <- fread(file, skip = 3, fill = TRUE) %>%
select(V1, V3, V4, V6, V7, V8, V16, V17) %>%
filter(V1 != "#")
names(domtbl) <- c("hit", "hit_length", "query", "query_length", "evalue", "score", "alignment_start", "alignment_end")
current_lake <- str_extract(file, pattern = paste(lakes$V1, collapse = "|"))
domtbl$lake <- current_lake
current_ORF <- str_extract(file, pattern = "ORF[^\\_]*")
# calc alignment length
domtbl$aln_length <- domtbl$alignment_end - domtbl$alignment_start
# prepare data for later filtering
domtbl$query_length <- as.numeric(domtbl$query_length)
domtbl$score <- as.numeric(domtbl$score)
domtbl <- domtbl %>%
filter(score >= 50)
# filter(score >= orf_df[orf_df$orf == current_ORF]$min_score) %>%
# filter(aln_length >= orf_df[orf_df$orf == current_ORF]$min_alignment_length)
big_df <- rbind(big_df, domtbl)
}
}
rm(orf_df, lakes, domtbl, current_lake, current_ORF)
contig_df <- data.table(table(big_df$hit))
contig_df$contig <- str_remove(contig_df$hit, pattern = "\\_length.*")
contig_df$contig_len <- as.numeric(str_remove(str_extract(contig_df$hit, "length\\_\\d*"), "length\\_"))
View(contig_df)
contig_df$contig <- str_remove(contig_df$V1, pattern = "\\_length.*")
contig_df$contig_len <- as.numeric(str_remove(str_extract(contig_df$V1, "length\\_\\d*"), "length\\_"))
contig_df %>%
filter(N >= 4)
contig_df <- contig_df %>%
filter(N >= 4)
View(big_df)
